
<!-- This document was automatically generated with bibtex2html 1.98
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     /usr/bin/bibtex2html -nodoc -dl -a -noabstract -nokeywords -o pubs2016_raw publications_bibtex/pubs2016.bib  -->


<dl>

<dt>
[<a name="abdallah2016digitaldata">1</a>]
</dt>
<dd>
S&nbsp;Abdallah, E&nbsp;Benetos, N&nbsp;Gold, S&nbsp;Hargreaves, T&nbsp;Weyde, and D&nbsp;Wolff.
 Digital music lab: A framework for analysing big music data.
 In <em>24th European Signal Processing Conference</em>, pages
  1118--1122. Budapest, Hungary, EURASIP, Aug 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#abdallah2016digitaldata">bib</a>&nbsp;]

</dd>


<dt>
[<a name="agres2016evaluationsystems">2</a>]
</dt>
<dd>
K&nbsp;Agres, J&nbsp;Forth, and GA&nbsp;Wiggins.
 Evaluation of musical creativity and musical metacreation systems.
 <em>Computers in Entertainment</em>, 14, Dec 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#agres2016evaluationsystems">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2967506">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="agres2016themusic">3</a>]
</dt>
<dd>
K&nbsp;Agres, D&nbsp;HERREMANS, L&nbsp;Bigo, and D&nbsp;Conklin.
 The effect of repetitive structure on enjoyment in uplifting trance
  music.
 In <em>14th International Conference for Music Perception and
  Cognition (ICMPC)</em>, pages 280--282, Jun 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#agres2016themusic">bib</a>&nbsp;]

</dd>


<dt>
[<a name="agres2016modelingmodels">4</a>]
</dt>
<dd>
KR&nbsp;Agres, S&nbsp;McGregor, K&nbsp;Rataj, M&nbsp;Purver, and GA&nbsp;Wiggins.
 Modeling metaphor perception with distributional semantics vector
  space models.
 In <em>CEUR Workshop Proceedings</em>, volume 1767, Jan 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#agres2016modelingmodels">bib</a>&nbsp;]

</dd>


<dt>
[<a name="allik2016ontologicalfeatures">5</a>]
</dt>
<dd>
A&nbsp;Allik, G&nbsp;Fazekas, and M&nbsp;Sandler.
 Ontological representation of audio features.
 In <em>SEMANTIC WEB - ISWC 2016, PT II</em>, volume 9982, pages 3--11,
  2016.
[&nbsp;<a href="pubs2016_raw_bib.html#allik2016ontologicalfeatures">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-46547-0_1">DOI</a>&nbsp;| 
<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&amp;SrcApp=PARTNER_APP\&amp;SrcAuth=LinksAMR\&amp;KeyUT=WOS:000389086600001\&amp;DestLinkType=FullRecord\&amp;DestApp=ALL_WOS\&amp;UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http</a>&nbsp;]

</dd>


<dt>
[<a name="alvaradodurangaussiananalysis">6</a>]
</dt>
<dd>
PA&nbsp;Alvarado&nbsp;Duran and DF&nbsp;STOWELL.
 Gaussian processes for music audio modelling and content analysis.
 In <em>IEEE International Workshop on Machine Learning for Signal
  Processing (MLSP)</em>, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#alvaradodurangaussiananalysis">bib</a>&nbsp;]

</dd>


<dt>
[<a name="barascud2016brainpatterns.">7</a>]
</dt>
<dd>
N&nbsp;Barascud, MT&nbsp;Pearce, TD&nbsp;Griffiths, KJ&nbsp;Friston, and M&nbsp;Chait.
 Brain responses in humans reveal ideal observer-like sensitivity to
  complex acoustic patterns.
 <em>Proc Natl Acad Sci U S A</em>, 113:E616--E625, Feb 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#barascud2016brainpatterns.">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1073/pnas.1508523113">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/26787854">http</a>&nbsp;]

</dd>


<dt>
[<a name="barthet2016crossroads:listening">8</a>]
</dt>
<dd>
M&nbsp;BARTHET, F&nbsp;Thalmann, G&nbsp;Fazekas, M&nbsp;Sandler, and G&nbsp;Wiggins.
 Crossroads: Interactive music systems transforming performance,
  production and listening.
 In <em>ACM Conference on Human Factors in Computing Systems (CHI),
  Workshop on Music and HCI</em>, May 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#barthet2016crossroads:listening">bib</a>&nbsp;]

</dd>


<dt>
[<a name="benetos2016detectionmodel">9</a>]
</dt>
<dd>
E&nbsp;Benetos, G&nbsp;Lafay, M&nbsp;Lagrange, and MD&nbsp;Plumbley.
 Detection of overlapping acoustic events using a
  temporally-constrained probabilistic model.
 In <em>IEEE International Conference on Acoustics, Speech, and
  Signal Processing</em>, pages 6450--6454, Emmanouil Benetos, Queen Mary
  University of London, School of Electronic Engineering and Computer Science,
  Mile End Road, London, E1 4NS, United Kingdom, Mar 2016. Shanghai, China,
  IEEE.
[&nbsp;<a href="pubs2016_raw_bib.html#benetos2016detectionmodel">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2016.7472919">DOI</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~emmanouilb/index.html">.html</a>&nbsp;]

</dd>


<dt>
[<a name="benetos2016automaticquartets">10</a>]
</dt>
<dd>
E&nbsp;BENETOS and R&nbsp;Schramm.
 Automatic transcription of vocal quartets.
 In <em>DMRN+11: Digital Music Research Network Workshop Proceedings
  2016</em>. Centre for Digital Music, Queen Mary University of London, Centre for
  Digital Music, Queen Mary University of London, Dec 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#benetos2016automaticquartets">bib</a>&nbsp;| 
<a href="https://qmro.qmul.ac.uk/xmlui/handle/123456789/19345">http</a>&nbsp;]

</dd>


<dt>
[<a name="cheng2016antranscription">11</a>]
</dt>
<dd>
T&nbsp;Cheng, M&nbsp;Mauch, E&nbsp;Benetos, and S&nbsp;Dixon.
 An attack/decay model for piano transcription.
 In <em>17th International Society for Music Information Retrieval
  Conference</em>, pages 584--590. New York, USA, ISMIR, Aug 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#cheng2016antranscription">bib</a>&nbsp;| 
<a href="https://wp.nyu.edu/ismir2016/">http</a>&nbsp;]

</dd>


<dt>
[<a name="chew2016playingtonality">12</a>]
</dt>
<dd>
E&nbsp;Chew.
 Playing with the edge: Tipping points and the role of tonality.
 <em>MUSIC PERCEPTION</em>, 33:344--366, Feb 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#chew2016playingtonality">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1525/MP.2016.33.03.344">DOI</a>&nbsp;| 
<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&amp;SrcApp=PARTNER_APP\&amp;SrcAuth=LinksAMR\&amp;KeyUT=WOS:000373749600007\&amp;DestLinkType=FullRecord\&amp;DestApp=ALL_WOS\&amp;UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http</a>&nbsp;]

</dd>


<dt>
[<a name="choi2016text-basedcomposition">13</a>]
</dt>
<dd>
K&nbsp;CHOI, M&nbsp;sandler, and G&nbsp;fazekas.
 Text-based lstm networks for automatic music composition.
 In <em>Conference on Computer Simulation of Musical Creativity</em>,
  Keunwoo Choi, Queen Mary University of London, EECS, Peter Landin Building,
  CS.319, London, E1 4FZ, United Kingdom, Jun 2016. Huddersfield, UK.
[&nbsp;<a href="pubs2016_raw_bib.html#choi2016text-basedcomposition">bib</a>&nbsp;]

</dd>


<dt>
[<a name="chourdakis2016automaticmodels">14</a>]
</dt>
<dd>
ET&nbsp;CHOURDAKIS and JD&nbsp;REISS.
 Automatic control of a digital reverberation effect using hybrid
  models.
 In <em>60th International Conference: DREAMS (Dereverberation and
  Reverberation of Audio, Music, and Speech)</em>. Leuven, Belgium, Jan 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#chourdakis2016automaticmodels">bib</a>&nbsp;]

</dd>


<dt>
[<a name="deman2016subjectivetool">15</a>]
</dt>
<dd>
BM&nbsp;DE&nbsp;MAN, N&nbsp;Jillings, D&nbsp;Moffat, JD&nbsp;Reiss, and R&nbsp;Stables.
 Subjective comparison of music production practices using the web
  audio evaluation tool.
 In <em>http://c4dm.eecs.qmul.ac.uk/events/wimp2/</em>. Queen Mary
  University of London, London, UK, Sep 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#deman2016subjectivetool">bib</a>&nbsp;]

</dd>


<dt>
[<a name="deman2016thecases">16</a>]
</dt>
<dd>
BM&nbsp;DE&nbsp;MAN and JD&nbsp;Reiss.
 The open multitrack testbed: Features, content and use cases.
 In <em>http://c4dm.eecs.qmul.ac.uk/events/wimp2/</em>. Queen Mary
  University of London, London, UK, Sep 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#deman2016thecases">bib</a>&nbsp;]

</dd>


<dt>
[<a name="dean2016algorithmically-generatedmusic">17</a>]
</dt>
<dd>
RT&nbsp;Dean and MT&nbsp;Pearce.
 Algorithmically-generated corpora that use serial compositional
  principles can contribute to the modeling of sequential pitch structure in
  non-tonal music.
 <em>Empirical Musicology Review</em>, 11:27--27, Jul 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#dean2016algorithmically-generatedmusic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.18061/emr.v11i1.4900">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="driedger2016template-basedsignals">18</a>]
</dt>
<dd>
J&nbsp;Driedger, S&nbsp;Balke, S&nbsp;Ewert, and M&nbsp;Müller.
 Template-based vibrato analysis in music signals.
 In <em>Proceedings of the International Society for Music
  Information Retrieval Conference (ISMIR)</em>, pages 239--245, New York, USA,
  2016.
[&nbsp;<a href="pubs2016_raw_bib.html#driedger2016template-basedsignals">bib</a>&nbsp;]

</dd>


<dt>
[<a name="ewert2016representationmethods">19</a>]
</dt>
<dd>
S&nbsp;Ewert.
 Representation of musical structure for a computationally feasible
  integration with audio-based methods.
 <em>Dagstuhl Reports (Computational Music Structure Analysis
  (Dagstuhl Seminar 16092))</em>, 6(2):175--176, Oct 2016.
 urn: urn:nbn:de:0030-drops-61415.
[&nbsp;<a href="pubs2016_raw_bib.html#ewert2016representationmethods">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.4230/DagRep.6.2.147">DOI</a>&nbsp;| 
<a href="http://drops.dagstuhl.de/opus/volltexte/2016/6141">http</a>&nbsp;]

</dd>


<dt>
[<a name="ewert2016pianoframework">20</a>]
</dt>
<dd>
S&nbsp;Ewert and M&nbsp;Sandler.
 Piano transcription in the studio using an extensible alternating
  directions framework.
 <em>IEEE/ACM Transactions on Audio Speech and Language Processing</em>,
  24:1983--1997, Nov 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#ewert2016pianoframework">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2016.2593801">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ewert2016score-informedrecordings">21</a>]
</dt>
<dd>
S&nbsp;Ewert, S&nbsp;Wang, M&nbsp;Müller, and M&nbsp;Sandler.
 Score-informed identification of missing and extra notes in piano
  recordings.
 In <em>Proceedings of the International Society for Music
  Information Retrieval Conference (ISMIR)</em>, pages 30--36, New York, USA, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#ewert2016score-informedrecordings">bib</a>&nbsp;]

</dd>


<dt>
[<a name="forth2016entrainingthinking">22</a>]
</dt>
<dd>
J&nbsp;FORTH, K&nbsp;AGRES, MRJ PURVER, and GA&nbsp;WIGGINS.
 Entraining idyot: timing in the information dynamics of thinking.
 <em>Frontiers in Psychology</em>, 7:1575--1575, Oct 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#forth2016entrainingthinking">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3389/fpsyg.2016.01575">DOI</a>&nbsp;| 
<a href="http://journal.frontiersin.org/article/10.3389/fpsyg.2016.01575/abstract">http</a>&nbsp;]

</dd>


<dt>
[<a name="Gingras2016">23</a>]
</dt>
<dd>
B&nbsp;Gingras, MT&nbsp;Pearce, M&nbsp;Goodchild, RT&nbsp;Dean, G&nbsp;Wiggins, and S&nbsp;McAdams.
 Linking melodic expectation to expressive performance timing and
  perceived musical tension.
 <em>Journal of experimental psychology. Human perception and
  performance</em>, 42:594--609, Apr 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#Gingras2016">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1037/xhp0000141">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="hansen2016nonlinearmusicology">24</a>]
</dt>
<dd>
NC&nbsp;Hansen, M&nbsp;Sadakata, and M&nbsp;Pearce.
 Nonlinear changes in the rhythm of european art music: Quantitative
  support for historical musicology.
 <em>Music Perception: An Interdisciplinary Journal</em>, 33:414--431,
  Apr 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#hansen2016nonlinearmusicology">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1525/mp.2016.33.4.414">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="hansen2016ifmusic">25</a>]
</dt>
<dd>
NC&nbsp;Hansen, P&nbsp;Vuust, and M&nbsp;Pearce.
 "if you have to ask, you'll never know": Effects of specialised
  stylistic expertise on predictive processing of music.
 <em>PLOS ONE</em>, 11:e0163584--e0163584, Oct 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#hansen2016ifmusic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1371/journal.pone.0163584">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="hayes2016asystem">26</a>]
</dt>
<dd>
K&nbsp;Hayes, M&nbsp;BARTHET, Y&nbsp;Wu, L&nbsp;Zhang, and N&nbsp;Bryan-Kinns.
 A participatory live music performance with the open symphony system.
 In <em>ACM Conference on Human Factors in Computing Systems (CHI):
  Interactivity</em>, May 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#hayes2016asystem">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2851581.2889471">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="healey2016betterphenomena">27</a>]
</dt>
<dd>
PGT HEALEY, C&nbsp;HOWES, J&nbsp;HOUGH, and MRJ PURVER.
 Better late than now-or-never: The case of interactive repair
  phenomena.
 <em>Behavioral and Brain Sciences</em>, 39:e76--e76, Jan 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#healey2016betterphenomena">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1017/S0140525X15000813">DOI</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/healey-et-al16bbs.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="heinrichs2016performance-ledapplications">28</a>]
</dt>
<dd>
C&nbsp;Heinrichs, A&nbsp;McPherson, and ACM.
 Performance-led design of computationally generated audio for
  interactive applications.
 In <em>PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE
  EMBEDDED AND EMBODIED INTERACTION (TEI16)</em>, pages 697--700, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#heinrichs2016performance-ledapplications">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2839462.2854109">DOI</a>&nbsp;| 
<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&amp;SrcApp=PARTNER_APP\&amp;SrcAuth=LinksAMR\&amp;KeyUT=WOS:000390588700100\&amp;DestLinkType=FullRecord\&amp;DestApp=ALL_WOS\&amp;UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http</a>&nbsp;]

</dd>


<dt>
[<a name="herremans2016morpheus:profiles">29</a>]
</dt>
<dd>
D&nbsp;HERREMANS and E&nbsp;Chew.
 Morpheus: Automatic music generation with recurrent pattern
  constraints and tension profiles.
 In <em>IEEE TENCON</em>. Singapore, Nov 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#herremans2016morpheus:profiles">bib</a>&nbsp;]

</dd>


<dt>
[<a name="herremans2016tensiontension.">30</a>]
</dt>
<dd>
D&nbsp;HERREMANS and E&nbsp;Chew.
 Tension ribbons: Quantifying and visualising tonal tension.
 In <em>Second International Conference on Technologies for Music
  Notation and Representation</em>, volume&nbsp;2, pages 8--18. Cambridge, May 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#herremans2016tensiontension.">bib</a>&nbsp;]

</dd>


<dt>
[<a name="holzapfel2016thetunes">31</a>]
</dt>
<dd>
A&nbsp;Holzapfel and E&nbsp;Benetos.
 The sousta corpus: Beat-informed automatic transcription of
  traditional dance tunes.
 In <em>17th International Society for Music Information Retrieval
  Conference</em>, pages 531--537. New York, USA, ISMIR, Aug 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#holzapfel2016thetunes">bib</a>&nbsp;| 
<a href="https://wp.nyu.edu/ismir2016/">http</a>&nbsp;]

</dd>


<dt>
[<a name="jack2016navigationfeedback">32</a>]
</dt>
<dd>
R&nbsp;Jack, T&nbsp;Stockman, A&nbsp;McPherson, and ACM.
 Navigation of pitch space on a digital musical instrument with
  dynamic tactile feedback.
 In <em>PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE
  EMBEDDED AND EMBODIED INTERACTION (TEI16)</em>, pages 3--11, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#jack2016navigationfeedback">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2839462.2839503">DOI</a>&nbsp;| 
<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&amp;SrcApp=PARTNER_APP\&amp;SrcAuth=LinksAMR\&amp;KeyUT=WOS:000390588700003\&amp;DestLinkType=FullRecord\&amp;DestApp=ALL_WOS\&amp;UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http</a>&nbsp;]

</dd>


<dt>
[<a name="jack2016effectinstrument">33</a>]
</dt>
<dd>
RH&nbsp;Jack, T&nbsp;Stockman, and A&nbsp;McPherson.
 Effect of latency on performer interaction and subjective quality
  assessment of a digital musical instrument.
 In <em>ACM International Conference Proceeding Series</em>, volume
  04-06-October-2016, pages 116--123, Oct 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#jack2016effectinstrument">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2986416.2986428">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="jillings2016webaudio">34</a>]
</dt>
<dd>
N&nbsp;Jillings, BM&nbsp;DE&nbsp;MAN, D&nbsp;Moffat, JD&nbsp;Reiss, and R&nbsp;Stables.
 Web audio evaluation tool: A framework for subjective assessment of
  audio.
 In J&nbsp;Freeman, A&nbsp;Lerch, and M&nbsp;Paradis, editors, <em>
  https://smartech.gatech.edu/handle/1853/54577/browse</em>. Atlanta, GA, USA, Apr
  2016.
[&nbsp;<a href="pubs2016_raw_bib.html#jillings2016webaudio">bib</a>&nbsp;| 
<a href="https://github.com/BrechtDeMan/WebAudioEvaluationTool">http</a>&nbsp;]

</dd>


<dt>
[<a name="jillings16WebAudio">35</a>]
</dt>
<dd>
Nicholas Jillings, Brecht De&nbsp;Man, David Moffat, and Joshua&nbsp;D. Reiss.
 Web audio evaluation tool: A framework for subjective assessment of
  audio.
 In <em>Proc. 2nd Web Audio Conference</em>. Web Audio Conference, April
  2016.
[&nbsp;<a href="pubs2016_raw_bib.html#jillings16WebAudio">bib</a>&nbsp;]

</dd>


<dt>
[<a name="kosta2016mappingapproach">36</a>]
</dt>
<dd>
K&nbsp;Kosta, R&nbsp;Ramirez, OF&nbsp;Bandtlow, and E&nbsp;Chew.
 Mapping between dynamic markings and performed loudness: A machine
  learning approach.
 <em>Journal of Mathematics and Music</em>, 10:149--172, Aug 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#kosta2016mappingapproach">bib</a>&nbsp;]

</dd>


<dt>
[<a name="lafay2016adetection">37</a>]
</dt>
<dd>
G&nbsp;Lafay, M&nbsp;Lagrange, M&nbsp;Rossignol, E&nbsp;Benetos, and A&nbsp;Roebel.
 A morphological model for simulating acoustic scenes and its
  application to sound event detection.
 <em>IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</em>, 24:1854--1864, Oct 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#lafay2016adetection">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2016.2587218">DOI</a>&nbsp;| 
<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7503122">http</a>&nbsp;]

</dd>


<dt>
[<a name="liang2016classificationsystem">38</a>]
</dt>
<dd>
B&nbsp;LIANG, G&nbsp;fazekas, A&nbsp;mcpherson, and M&nbsp;sandler.
 Classification of piano pedaling techniques using gesture data from a
  non-intrusive measurement system.
 In <em>DMRN+11: Digital Music Research Network Workshop Proceedings
  2016</em>. Centre for Digital Music, Queen Mary University of London, Centre for
  Digital Music, Queen Mary University of London, Dec 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#liang2016classificationsystem">bib</a>&nbsp;| 
<a href="https://qmro.qmul.ac.uk/xmlui/handle/123456789/19345">http</a>&nbsp;]

</dd>


<dt>
[<a name="mazzoni2016moody:music">39</a>]
</dt>
<dd>
A&nbsp;Mazzoni and N&nbsp;Bryan-Kinns.
 Moody: Haptic sensations to enhance mood in film music.
 In <em>DIS 2016 Companion - Proceedings of the 2016 ACM Conference
  on Designing Interactive Systems: Fuse</em>, pages 21--24, Jun 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#mazzoni2016moody:music">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2908805.2908811">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mcpherson2016designinginstrument">40</a>]
</dt>
<dd>
A&nbsp;MCPHERSON, A&nbsp;Chamberlain, A&nbsp;Hazzard, S&nbsp;McGrath, and S&nbsp;Benford.
 Designing for exploratory play with a hackable digital musical
  instrument.
 In <em>ACM Conference on Designing Interactive Systems</em>. Brisbane,
  Australia, Jun 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#mcpherson2016designinginstrument">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2901790.2901831">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mcpherson2016action-soundenough?">41</a>]
</dt>
<dd>
AP&nbsp;McPherson, RH&nbsp;Jack, and G&nbsp;Moro.
 Action-sound latency: Are our tools fast enough?
 In <em>Proceedings of the International Conference on New Interfaces
  for Musical Expression, Brisbane, Queensland, Australia, July 11-15, 2016</em>.
  Griffith University, South Bank, Brisbane, Queensland, Australia, Griffith
  University, Jul 2016.
 Licensed under a Creative Commons Attribution 4.0 International
  License (CC BY 4.0). Copyright remains with the author(s).
[&nbsp;<a href="pubs2016_raw_bib.html#mcpherson2016action-soundenough?">bib</a>&nbsp;| 
<a href="https://nime2016.wordpress.com/">http</a>&nbsp;]

</dd>


<dt>
[<a name="mehrabi2016towardssounds">42</a>]
</dt>
<dd>
A&nbsp;MEHRABI, S&nbsp;Dixon, and M&nbsp;Sandler.
 Towards a comprehensive dataset of vocal imitations of drum sounds.
 In <em>2nd AES Workshop on Intelligent Music Production</em>, Sep 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#mehrabi2016towardssounds">bib</a>&nbsp;]

</dd>


<dt>
[<a name="mengal16Weapon">43</a>]
</dt>
<dd>
Lucas Mengual, David Moffat, and Joshua&nbsp;D. Reiss.
 Modal synthesis of weapon sounds.
 In <em>Proc. Audio Engineering Society Conference: 61st
  International Conference: Audio for Games</em>. Audio Engineering Society, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#mengal16Weapon">bib</a>&nbsp;]

</dd>


<dt>
[<a name="metatla2016sonificationtasks">44</a>]
</dt>
<dd>
O&nbsp;Metatla, N&nbsp;Bryan-Kinns, T&nbsp;Stockman, and F&nbsp;Martin.
 Sonification of reference markers for auditory graphs: effects on
  non-visual estimation tasks.
 <em>PeerJ Computer Science</em>, 2, Apr 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#metatla2016sonificationtasks">bib</a>&nbsp;]

</dd>


<dt>
[<a name="metatla2016tapinterface">45</a>]
</dt>
<dd>
O&nbsp;Metatla, N&nbsp;Correia, F&nbsp;Martin, N&nbsp;Bryan-Kinns, and T&nbsp;Stockman.
 Tap the shapetones: Exploring the effects of crossmodal congruence in
  an audio-visual interface.
 pages 1055--1066, 2016.
 proceedings: Proceedings of the 2016 CHI Conference on Human Factors
  in Computing Systems.
[&nbsp;<a href="pubs2016_raw_bib.html#metatla2016tapinterface">bib</a>&nbsp;]

</dd>


<dt>
[<a name="metatla2016audio-hapticapproach">46</a>]
</dt>
<dd>
O&nbsp;Metatla, F&nbsp;Martin, A&nbsp;Parkinson, N&nbsp;Bryan-Kinns, T&nbsp;Stockman, and A&nbsp;Tanaka.
 Audio-haptic interfaces for digital audio workstations: A
  participatory design approach.
 <em>Journal on Multimodal User Interfaces</em>, 10:247--258, Sep 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#metatla2016audio-hapticapproach">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s12193-016-0217-8">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="moffat16Dereverberation">47</a>]
</dt>
<dd>
David Moffat and Joshua&nbsp;D. Reiss.
 Implementation and assessment of joint source separation and
  dereverberation.
 In <em>Proc. Audio Engineering Society Conference: 60th
  International Conference: DREAMS (Dereverberation and Reverberation of Audio,
  Music, and Speech)</em>. Audio Engineering Society, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#moffat16Dereverberation">bib</a>&nbsp;]

</dd>


<dt>
[<a name="moro2016makingdata">48</a>]
</dt>
<dd>
G&nbsp;MORO, A&nbsp;Bin, RH&nbsp;Jack, C&nbsp;Heinrichs, and AP&nbsp;McPherson.
 Making high-performance embedded instruments with bela and pure data.
 In <em>International Conference on Live Interfaces</em>. University of
  Sussex, University of Sussex, Jun 2016.
 This hands-on workshop introduces participants to Bela, an embedded
  platform for ultra-low latency audio and sensor processing.
[&nbsp;<a href="pubs2016_raw_bib.html#moro2016makingdata">bib</a>&nbsp;| 
<a href="http://www.liveinterfaces.org/proceedings2016.html">.html</a>&nbsp;]

</dd>


<dt>
[<a name="ohanlon2016annmf">49</a>]
</dt>
<dd>
K&nbsp;O'Hanlon, MB&nbsp;Sandler, and IEEE.
 An iterative hard thresholding approach to l(0) sparse hellinger nmf.
 In <em>2016 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND
  SIGNAL PROCESSING PROCEEDINGS</em>, pages 4737--4741, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#ohanlon2016annmf">bib</a>&nbsp;| 
<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&amp;SrcApp=PARTNER_APP\&amp;SrcAuth=LinksAMR\&amp;KeyUT=WOS:000388373404177\&amp;DestLinkType=FullRecord\&amp;DestApp=ALL_WOS\&amp;UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http</a>&nbsp;]

</dd>


<dt>
[<a name="ohanlon2016compositionaldistance">50</a>]
</dt>
<dd>
K&nbsp;O'Hanlon, MB&nbsp;Sandler, and IEEE.
 Compositional chroma estimation using powered euclidean distance.
 In <em>2016 24TH EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO)</em>,
  pages 1237--1241, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#ohanlon2016compositionaldistance">bib</a>&nbsp;| 
<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&amp;SrcApp=PARTNER_APP\&amp;SrcAuth=LinksAMR\&amp;KeyUT=WOS:000391891900236\&amp;DestLinkType=FullRecord\&amp;DestApp=ALL_WOS\&amp;UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http</a>&nbsp;]

</dd>


<dt>
[<a name="panteli2016automaticcollections">51</a>]
</dt>
<dd>
M&nbsp;Panteli, E&nbsp;Benetos, and S&nbsp;Dixon.
 Automatic detection of outliers in world music collections.
 In <em>Fourth International Conference on Analytical Approaches to
  World Music (AAWM 2016)</em>, Maria Panteli, Queen Mary University of London,
  School of Electronic Enginering and Computer Science, Mile End Road, London,
  E1 4NS, United Kingdom, Jun 2016. New York, USA.
[&nbsp;<a href="pubs2016_raw_bib.html#panteli2016automaticcollections">bib</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mp305/">http</a>&nbsp;]

</dd>


<dt>
[<a name="panteli2016learningmusic">52</a>]
</dt>
<dd>
M&nbsp;Panteli, E&nbsp;Benetos, and S&nbsp;Dixon.
 Learning a feature space for similarity in world music.
 In <em>17th International Society for Music Information Retrieval
  Conference</em>, pages 538--544. New York, USA, ISMIR, Aug 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#panteli2016learningmusic">bib</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mp305/">http</a>&nbsp;]

</dd>


<dt>
[<a name="pearce2016amusic">53</a>]
</dt>
<dd>
MT&nbsp;PEARCE and E&nbsp;Schubert.
 A new look at musical expectancy: The veridical versus the general in
  the mental organization of music.
 In R&nbsp;Kronland-Martinet, M&nbsp;Aramaki, and S&nbsp;Ystad, editors, <em>Music,
  Mind, and Embodiment</em>, pages 358--370. Springer, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#pearce2016amusic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-46282-0_23">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="Pearce2016">54</a>]
</dt>
<dd>
MT&nbsp;Pearce, DW&nbsp;Zaidel, O&nbsp;Vartanian, M&nbsp;Skov, H&nbsp;Leder, A&nbsp;Chatterjee, and M&nbsp;Nadal.
 Neuroaesthetics: The cognitive neuroscience of aesthetic experience.
 <em>Perspectives on psychological science : a journal of the
  Association for Psychological Science</em>, 11:265--279, Mar 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#Pearce2016">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1177/1745691615621274">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="quinton2016estimationdescriptor">55</a>]
</dt>
<dd>
E&nbsp;QUINTON, M&nbsp;Sandler, and S&nbsp;Dixon.
 Estimation of the reliability of multiple rhythm features extraction
  from a single descriptor.
 <em>IEEE International Conference on Acoustics Speech and Signal
  Processing</em>, Apr 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#quinton2016estimationdescriptor">bib</a>&nbsp;]

</dd>


<dt>
[<a name="reiss2016aevaluation">56</a>]
</dt>
<dd>
J&nbsp;REISS.
 A meta-analysis of high resolution audio perceptual evaluation.
 <em>Journal of the Audio Engineering Society</em>, 64:364--379, Jun
  2016.
[&nbsp;<a href="pubs2016_raw_bib.html#reiss2016aevaluation">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/jaes.2016.0015">DOI</a>&nbsp;| 
<a href="tp://www.aes.org/">www:</a>&nbsp;]

</dd>


<dt>
[<a name="rodriguezalgarra2016analysingmusic?">57</a>]
</dt>
<dd>
F&nbsp;RODRIGUEZ&nbsp;ALGARRA, BL&nbsp;Sturm, and H&nbsp;Maruri-Aguilar.
 Analysing scattering-based music content analysis systems: Where's
  the music?
 In <em>17th International Society for Music Information Retrieval
  Conference (ISMIR 2016)</em>. New York, NY, USA, Aug 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#rodriguezalgarra2016analysingmusic?">bib</a>&nbsp;]

</dd>


<dt>
[<a name="rodriguez-serrano2016arecordings">58</a>]
</dt>
<dd>
FJ&nbsp;Rodriguez-Serrano, S&nbsp;Ewert, P&nbsp;Vera-Candeas, and M&nbsp;Sandler.
 A score-informed shift-invariant extension of complex matrix
  factorization for improving the separation of overlapped partials in music
  recordings.
 In <em>Proceedings of the IEEE International Conference on
  Acoustics, Speech, and Signal Processing (ICASSP)</em>, Shanghai, China, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#rodriguez-serrano2016arecordings">bib</a>&nbsp;]

</dd>


<dt>
[<a name="Sigtia2016">59</a>]
</dt>
<dd>
S&nbsp;Sigtia, E&nbsp;BENETOS, and S&nbsp;Dixon.
 An end-to-end neural network for polyphonic piano music
  transcription.
 <em>IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</em>, 24:927--939, May 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#Sigtia2016">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2016.2533858">DOI</a>&nbsp;| 
<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7416164">http</a>&nbsp;]

</dd>


<dt>
[<a name="song2016perceivedmodels">60</a>]
</dt>
<dd>
Y&nbsp;Song, S&nbsp;Dixon, MT&nbsp;Pearce, and AR&nbsp;Halpern.
 Perceived and induced emotion responses to popular music: Categorical
  and dimensional models.
 <em>Music Perception</em>, 33:472--492, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#song2016perceivedmodels">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1525/MP.2016.33.4.472">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stables2016semanticproduction">61</a>]
</dt>
<dd>
R&nbsp;Stables, B&nbsp;De&nbsp;Man, S&nbsp;Enderby, JD&nbsp;Reiss, G&nbsp;Fazekas, and T&nbsp;Wilmering.
 Semantic description of timbral transformations in music production.
 In <em>MM 2016 - Proceedings of the 2016 ACM Multimedia Conference</em>,
  pages 337--341, Oct 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#stables2016semanticproduction">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2964284.2967238">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2016reflectionsseeking">62</a>]
</dt>
<dd>
AG&nbsp;STOCKMAN and D&nbsp;Al-Thani.
 Reflections on the research methods used in an investigation of
  cross-modal collaborative information seeking.
 In <em>The 5th International Workshop onn Collaboration:
  Human-Centered Issues &amp; Interactivity Design, as part of The 2016
  International Conference on Collaboration Technologies and Systems, Florida,
  USA, October-November 2016.</em> Florida, USA, Oct 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#stockman2016reflectionsseeking">bib</a>&nbsp;]

</dd>


<dt>
[<a name="stowell2016detailedsongbirds">63</a>]
</dt>
<dd>
DF&nbsp;STOWELL, LF&nbsp;Gill, and D&nbsp;Clayton.
 Detailed temporal structure of communication networks in groups of
  songbirds.
 <em>Journal of the Royal Society Interface</em>, 13, Jun 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#stowell2016detailedsongbirds">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1098/rsif.2016.0296">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stowellbirdchallenge">64</a>]
</dt>
<dd>
DF&nbsp;STOWELL, M&nbsp;Wood, Y&nbsp;Stylianou, and H&nbsp;Glotin.
 Bird detection in audio: A survey and a challenge.
 In <em>IEEE International Workshop on Machine Learning for Signal
  Processing (MLSP)</em>, 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#stowellbirdchallenge">bib</a>&nbsp;]

</dd>


<dt>
[<a name="sturm2016``horsesystems">65</a>]
</dt>
<dd>
BLT STURM.
 &ldquo;horse&rdquo; inside: Seeking causes of the behaviours of music content
  analysis systems.
 <em>ACM Computers in Entertainment</em>, 9(39), Dec 2016.
 OA Monitor Exercise.
[&nbsp;<a href="pubs2016_raw_bib.html#sturm2016``horsesystems">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2967507">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="subramanian2016umaguitarra">66</a>]
</dt>
<dd>
A&nbsp;Subramanian, N&nbsp;Cunha, and D&nbsp;HERREMANS.
 Uma abordagem baseada em programação linear inteira para a
  geração de solos de guitarra.
 In <em>XLVIII Simpósio Brasileiro de Pesquisa Operacional (SBPO)</em>.
  Vitoria, Brasil, Sep 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#subramanian2016umaguitarra">bib</a>&nbsp;]

</dd>


<dt>
[<a name="sulyok2016evolvingcomposer">67</a>]
</dt>
<dd>
C&nbsp;Sulyok, A&nbsp;MCPHERSON, and C&nbsp;Harte.
 Evolving the process of a virtual composer.
 <em>Natural Computing</em>, Jun 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#sulyok2016evolvingcomposer">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s11047-016-9561-6">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="THALMANN">68</a>]
</dt>
<dd>
FS&nbsp;THALMANN, perez carillo, fazekas, wiggins, and sandler.
 The mobile audio ontology: Experiencing dynamic music objects on
  mobile devices.
 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#THALMANN">bib</a>&nbsp;]

</dd>


<dt>
[<a name="theodorou2016exploringperformances">69</a>]
</dt>
<dd>
L&nbsp;Theodorou, PGT Healey, and F&nbsp;Smeraldi.
 Exploring audience behaviour during contemporary dance performances.
 In <em>ACM International Conference Proceeding Series</em>, volume
  05-06-July-2016, Jul 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#theodorou2016exploringperformances">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2948910.2948928">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="tian2016towardsprinciples">70</a>]
</dt>
<dd>
M&nbsp;TIAN and MARKB Sandler.
 Towards music structural segmentation across genres: Features,
  structural hypotheses and annotation principles.
 <em>ACM Transactions on Intelligent Systems and Technology</em>, Nov
  2016.
[&nbsp;<a href="pubs2016_raw_bib.html#tian2016towardsprinciples">bib</a>&nbsp;]

</dd>


<dt>
[<a name="turchet16Footstep">71</a>]
</dt>
<dd>
Luca Turchet, David Moffat, Ana Tajadura-Jim&eacute;nez, Joshua&nbsp;D. Reiss, and Tony
  Stockman.
 What do your footsteps sound like? an investigation on interactive
  footstep sounds adjustment.
 <em>Applied Acoustics</em>, 2016.
 "In Press".
[&nbsp;<a href="pubs2016_raw_bib.html#turchet16Footstep">bib</a>&nbsp;]

</dd>


<dt>
[<a name="valero-mas2016classification-basedtranscription">72</a>]
</dt>
<dd>
JJ&nbsp;Valero-Mas, E&nbsp;Benetos, and JM&nbsp;Iñesta.
 Classification-based note tracking for automatic music transcription.
 In <em>
  https://sites.google.com/site/musicmachinelearning16/proceedings</em>, pages
  61--65. Riva del Garda, Italy, Sep 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#valero-mas2016classification-basedtranscription">bib</a>&nbsp;| 
<a href="https://sites.google.com/site/musicmachinelearning16/">http</a>&nbsp;]

</dd>


<dt>
[<a name="volk2016musiccomputation">73</a>]
</dt>
<dd>
A&nbsp;Volk, E&nbsp;Chew, EH&nbsp;Margulis, and C&nbsp;Anagnostopoulou.
 Music similarity: Concepts, cognition and computation.
 <em>JOURNAL OF NEW MUSIC RESEARCH</em>, 45:207--209, Sep 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#volk2016musiccomputation">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/09298215.2016.1232412">DOI</a>&nbsp;| 
<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&amp;SrcApp=PARTNER_APP\&amp;SrcAuth=LinksAMR\&amp;KeyUT=WOS:000385541200001\&amp;DestLinkType=FullRecord\&amp;DestApp=ALL_WOS\&amp;UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http</a>&nbsp;]

</dd>


<dt>
[<a name="vlimki2016allfrontiers">74</a>]
</dt>
<dd>
V&nbsp;Välimäki and J&nbsp;Reiss.
 All about audio equalization: Solutions and frontiers.
 <em>Applied Sciences</em>, 6:129--129, May 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#vlimki2016allfrontiers">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/app6050129">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wang2016anmicrophones">75</a>]
</dt>
<dd>
L&nbsp;Wang, TK&nbsp;Hon, JD&nbsp;Reiss, and A&nbsp;Cavallaro.
 An iterative approach to source counting and localization using two
  distant microphones.
 <em>IEEE/ACM Transactions on Audio Speech and Language Processing</em>,
  24:1079--1093, Jun 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#wang2016anmicrophones">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2016.2533859">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wang2016self-localizationarrivals">76</a>]
</dt>
<dd>
L&nbsp;Wang, TK&nbsp;Hon, JD&nbsp;Reiss, and A&nbsp;Cavallaro.
 Self-localization of ad-hoc arrays using time difference of arrivals.
 <em>IEEE Transactions on Signal Processing</em>, 64:1018--1033, Feb
  2016.
[&nbsp;<a href="pubs2016_raw_bib.html#wang2016self-localizationarrivals">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TSP.2015.2498130">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wang2016robustperformances">77</a>]
</dt>
<dd>
S&nbsp;Wang, S&nbsp;Ewert, and S&nbsp;Dixon.
 Robust and efficient joint alignment of multiple musical
  performances.
 <em>IEEE/ACM Transactions on Audio Speech and Language Processing</em>,
  24:2132--2145, Nov 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#wang2016robustperformances">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2016.2598318">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wilkinson2016performablemapping">78</a>]
</dt>
<dd>
WJ&nbsp;WILKINSON, D&nbsp;stowell, and J&nbsp;reiss.
 Performable spectral synthesis via low-dimensional modelling and
  control mapping.
 In <em>DMRN+11: Digital Music Research Network Workshop Proceedings
  2016</em>. Centre for Digital Music, Queen Mary University of London, Centre for
  Digital Music, Queen Mary University of London, Dec 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#wilkinson2016performablemapping">bib</a>&nbsp;| 
<a href="https://qmro.qmul.ac.uk/xmlui/handle/123456789/19345">http</a>&nbsp;]

</dd>


<dt>
[<a name="wilmering2016aufx-o:workflows">79</a>]
</dt>
<dd>
T&nbsp;Wilmering, G&nbsp;Fazekas, and MB&nbsp;Sandler.
 Aufx-o: Novel methods for the representation of audio processing
  workflows.
 In <em>Lecture Notes in Computer Science (including subseries
  Lecture Notes in Artificial Intelligence and Lecture Notes in
  Bioinformatics)</em>, volume 9982 LNCS, pages 229--237, Jan 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#wilmering2016aufx-o:workflows">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-46547-0_24">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="yang2016ava:analysis">80</a>]
</dt>
<dd>
L&nbsp;YANG, SAYID-KHALID Rajab, and E&nbsp;Chew.
 Ava: A graphical user interface for automatic vibrato and portamento
  detection and analysis.
 In <em>the 42nd International Computer Music Conference</em>. Utrecht,
  The Netherlands, Sep 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#yang2016ava:analysis">bib</a>&nbsp;]

</dd>


<dt>
[<a name="zhang2016acase">81</a>]
</dt>
<dd>
L&nbsp;Zhang, Y&nbsp;Wu, and M&nbsp;BARTHET.
 A web application for audience participation in live music
  performance: The open symphony use case.
 In <em>International Conference on New Interfaces for Musical
  Expression</em>, Jul 2016.
[&nbsp;<a href="pubs2016_raw_bib.html#zhang2016acase">bib</a>&nbsp;]

</dd>
</dl><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.98.</em></p>
