<h1>pubs2015.bib</h1><a name="Robertson:2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Robertson:2015">Robertson:2015</a>,
  title = {Event-based Multitrack Alignment using a Probabilistic Framework},
  author = {Robertson, A. and Plumbley, M. D.},
  journal = {Journal of New Music Research},
  year = {2015},
  number = {2},
  pages = {71-82},
  volume = {44},
  abstract = { This paper presents a Bayesian probabilistic framework for real-time alignment of a recording or score with a live performance using an event-based approach. Multitrack audio files are processed using existing onset detection and harmonic analysis algorithms to create a representation of a musical performance as a sequence of time-stamped events. We propose the use of distributions for the position and relative speed which are sequentially updated in real-time according to Bayesâ€™ theorem. We develop the methodology for this approach by describing its application in the case of matching a single MIDI track and then extend this to the case of multitrack recordings. An evaluation is presented that contrasts ourmultitrack alignment method with state-of-the-art alignment techniques. },
  doi = {10.1080/09298215.2015.1009839}
}
</pre>

<a name="Stowell:2015b"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Stowell:2015b">Stowell:2015b</a>,
  title = {Acoustic event detection for multiple overlapping similar sources },
  author = {Stowell, D. and Clayton, D.},
  booktitle = {Applications of Signal Processing to Audio and Acoustics (WASPAA), 2015 IEEE Workshop on},
  year = {2015},
  abstract = {Many current paradigms for acoustic event detection (AED) are not adapted to the organic variability of natural sounds, and/or they assume a limit on the number of simultaneous sources: often only one source, or one source of each type, may be active. These aspects are highly undesirable for applications such as bird population monitoring. We introduce a simple method modelling the onsets, durations and offsets of acoustic events to avoid intrinsic limits on polyphony or on inter-event temporal patterns. We evaluate the method in a case study with over 3000 zebra finch calls. In comparison against a HMM-based method we find it more accurate at recovering acoustic events, and more robust for estimating calling rates. },
  url = {<a href="http://arxiv.org/abs/1503.07150">http://arxiv.org/abs/1503.07150</a>}
}
</pre>

<a name="Stowell:2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Stowell:2015">Stowell:2015</a>,
  title = {Detection and classification of acoustic scenes and events},
  author = {Stowell, D. and Giannoulis, D. and Benetos, E. and Lagrange, M. and Plumbley, M. D.},
  journal = {{IEEE} Transactions on Multimedia},
  year = {2015},
  month = {October},
  number = {10},
  pages = {1733--1746},
  volume = {17},
  abstract = {For intelligent systems to make best use of the audio modality, it is important that they can recognise not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organisation of the challenge, so that our experience as challenge hosts may be useful to those organising challenges in similar domains. We created new audio datasets and baseline systems for the challenge: these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmark for further research in general-purpose machine listening.},
  doi = {10.1109/TMM.2015.2428998}
}
</pre>

<a name="Kereliuk2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Kereliuk2015">Kereliuk2015</a>,
  title = {Deep Learning and Music Adversaries},
  author = {Kereliuk, C and Sturm, BL and Larsen, J},
  journal = {IEEE Transactions on Multimedia},
  year = {2015},
  month = {Nov},
  pages = {2059--2071},
  volume = {17},
  doi = {10.1109/TMM.2015.2478068},
  eissn = {1941-0077},
  issn = {1520-9210},
  issue = {11},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Rohrmeier2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Rohrmeier2015">Rohrmeier2015</a>,
  title = {Principles of structure building in music, language and animal song},
  author = {Rohrmeier, M and Zuidema, W and Wiggins, GA and Scharff, C},
  journal = {PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES},
  year = {2015},
  month = {Mar},
  number = {UNSP 20140097},
  pages = {107--121},
  volume = {370},
  day = {19},
  doi = {10.1098/rstb.2014.0097},
  issn = {0962-8436},
  issue = {1664},
  keyword = {music},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04},
  url = {<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000350537300010\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000350537300010\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a</a>}
}
</pre>

<a name="Sturm"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Sturm">Sturm</a>,
  title = {El Caballo Viejo? Latin genre recognition with deep learning and spectral periodicity},
  author = {Sturm and Kereliuk, C and Larsen, J},
  year = {2015},
  organization = {QMUL},
  abstract = {The ``winning'' system in the 2013 MIREX Latin Genre Classification Task was a deep neural network trained with simple features. An explanation for its winning performance has yet to be found. In previous work, we built similar systems using the \em BALLROOM music dataset, and found their performances to be greatly affected by slightly changing the tempo of the music of a test recording. In the MIREX task, however, systems are trained and tested using the \em Latin Music Dataset (LMD), which is 4.5 times larger than \em BALLROOM, and which does not seem to show as strong a relationship between tempo and label as \em BALLROOM. In this paper, we reproduce the ``winning'' deep learning system using \em LMD, and measure the effects of time dilation on its performance. We find that tempo changes of at most \$\pm 6\$\\% greatly diminish and improve its performance. Interpreted with the low-level nature of the input features, this supports the conclusion that the system is exploiting some low-level absolute time characteristics to reproduce ground truth in \em LMD.},
  conference = {Mathematics and Computation in Music},
  doi = {10.1007/978-3-319-20603-5_34},
  filedday = {6},
  filedmonth = {Mar},
  filedyear = {2015},
  finishday = {25},
  finishmonth = {Jun},
  finishyear = {2015},
  isbn = {978-3-319-20602-8},
  owner = {dan},
  publicationstatus = {published},
  startday = {22},
  startmonth = {Jun},
  startyear = {2015},
  timestamp = {2016.04.04},
  url = {<a href="http://link.springer.com/chapter/10.1007/978-3-319-20603-5_34">http://link.springer.com/chapter/10.1007/978-3-319-20603-5_34</a>}
}
</pre>

<a name="Sturma"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Sturma">Sturma</a>,
  title = {Deep Learning, Audio Adversaries, and Music Content Analysis},
  author = {Sturm and Kereliuk, C and Larsen, J},
  year = {2015},
  organization = {Mohonk, NY},
  abstract = {We present the concept of \em adversarial audio in the context of deep neural networks (DNNs) for music content analysis. An adversary is an algorithm that makes minor perturbations to an input that cause major repercussions to the system response. In particular, we design an adversary for a DNN that takes as input short-time spectral magnitudes of recorded music and outputs a high-level music descriptor. We demonstrate how this adversary can make the DNN behave in any way with only extremely minor changes to the music recording signal. We show that the adversary cannot be neutralised by a simple filtering of the input. Finally, we discuss adversaries in the broader context of the evaluation of music content analysis systems.},
  conference = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  filedday = {26},
  filedmonth = {Jun},
  filedyear = {2015},
  finishday = {21},
  finishmonth = {Oct},
  finishyear = {2015},
  owner = {dan},
  startday = {18},
  startmonth = {Oct},
  startyear = {2015},
  timestamp = {2016.04.04}
}
</pre>

<a name="Sturmb"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Sturmb">Sturmb</a>,
  title = {The scientific evaluation of music content analysis systems: Valid empirical foundations for future real-world impact},
  author = {Sturm, BLT and Maruri-Aguilar, H and Parker, B and Grossmann, H},
  year = {2015},
  organization = {Lille, France},
  abstract = {We discuss the problem of music content analysis within the formal framework of experimental design.},
  conference = {International Conference on Machine Learning},
  finishday = {11},
  finishmonth = {Jul},
  finishyear = {2015},
  owner = {dan},
  startday = {6},
  startmonth = {Jul},
  startyear = {2015},
  timestamp = {2016.04.04}
}
</pre>

<a name="Wiggins2015a"></a><pre>
@incollection{<a href="input/pubs2015_raw.html#Wiggins2015a">Wiggins2015a</a>,
  title = {IDyOT: A Computational Theory of Creativity as Everyday Reasoning from Learned Information},
  author = {Wiggins, GA and Forth, JC},
  booktitle = {Computational Creativity Research: Towards Creative Machines},
  publisher = {Atlantis Press},
  year = {2015},
  editor = {Besold, TR and Schorlemmer, M and Smaill, A},
  number = {7},
  pages = {127--148},
  series = {Atlantis Thinking Machines},
  abstract = {We present progress towards a computational cognitive architecture, IDyOT (Information Dynamics of Thinking) that is intended to account for cer- tain aspects of human creativity and other forms of cognitive processing in terms of a pre-conscious predictive loop. The theory is motivated in terms of the evolutionary pressure to be efficient. It makes several predictions that may be tested by building computational implementations and studying their behaviour.},
  doi = {10.2991/978-94-6239-085-0},
  isbn = {978-94-6239-084-3},
  numberofpieces = {19},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.springer.com/gb/book/9789462390843">http://www.springer.com/gb/book/9789462390843</a>}
}
</pre>

<a name="Wiggins2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Wiggins2015">Wiggins2015</a>,
  title = {The evolutionary roots of creativity: mechanisms and motivations},
  author = {Wiggins, GA and Tyack, P and Scharff, C and Rohrmeier, M},
  journal = {PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES},
  year = {2015},
  month = {Mar},
  number = {ARTN 20140099},
  pages = {129--137},
  volume = {370},
  day = {19},
  doi = {10.1098/rstb.2014.0099},
  issn = {0962-8436},
  issue = {1664},
  keyword = {creativity},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04},
  url = {<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000350537300012\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000350537300012\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a</a>}
}
</pre>

<a name="Ewert2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Ewert2015">Ewert2015</a>,
  title = {A DYNAMIC PROGRAMMING VARIANT OF NON-NEGATIVE MATRIX DECONVOLUTION FOR THE TRANSCRIPTION OF STRUCK STRING INSTRUMENTS},
  author = {Ewert, S and Plumbley, MD and Sandler, M and IEEE},
  booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING (ICASSP)},
  year = {2015},
  pages = {569--573},
  issn = {1520-6149},
  keyword = {Non-Negative Matrix Deconvolution},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04},
  url = {<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000368452400114\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000368452400114\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a</a>}
}
</pre>

<a name="Tian2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Tian2015">Tian2015</a>,
  title = {On the use of the tempogram to describe audio content and its application to Music structural segmentation},
  author = {Tian, M and Fazekas, G and Black, DAA and Sandler, M},
  booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  year = {2015},
  month = {Jan},
  pages = {419--423},
  volume = {2015-August},
  abstract = {This paper presents a new set of audio features to describe music content based on tempo cues. Tempogram, a mid-level representation of tempo information, is constructed to characterize tempo variation and local pulse in the audio signal. We introduce a collection of novel tempogram-based features inspired by musicological hypotheses about the relation between music structure and its rhythmic components prominent at different metrical levels. The strength of these features is demonstrated in music structural segmentation, an important task in Music information retrieval (MIR), using several published popular music datasets. Results indicate that incorporating tempo information into audio segmentation is a promising new direction.},
  day = {1},
  doi = {10.1109/ICASSP.2015.7178003},
  isbn = {9781467369978},
  issn = {1520-6149},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Saari2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Saari2015">Saari2015</a>,
  title = {Genre-adaptive Semantic Computing and Audio-based Modelling for Music Mood Annotation},
  author = {Saari, P and Fazekas, G and Eerola, T and Barthet, M and Lartillot, O and Sandler, M},
  journal = {IEEE Transactions on Affective Computing},
  year = {2015},
  pages = {1--1},
  doi = {10.1109/TAFFC.2015.2462841},
  issn = {1949-3045},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="FREEMAN2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#FREEMAN2015">FREEMAN2015</a>,
  title = {A concise taxonomy for describing data as an art material.},
  author = {FREEMAN, J and SANDLER, M and WIGGINS, G and STARKS, G},
  booktitle = {Proceedings of the IEEE VIS Arts Program (VISAP)},
  year = {2015},
  month = {Oct},
  organization = {Chicago, Illinois},
  pages = {22--29},
  publisher = {IEEE},
  abstract = {How can we describe data when used as an art material? As the number of artists using data in their work increases, so too must our ability to describe the material in a way that is understood by both specialist and general audiences alike. In this paper we review existing vocabularies, glossaries, and taxonomies of data, and propose our own concise taxonomy. We present a number of examples of how existing data art works are described, and demonstrate our taxonomy by applying it to these works. To conclude we propose the adoption of this concise taxonomy by artists, critics, and curators, and suggest that on-going refinement of the taxonomy takes place through crowd-sourced knowledge sharing on the web.},
  conference = {IEEE VIS},
  day = {26},
  finishday = {30},
  finishmonth = {Oct},
  finishyear = {2015},
  keyword = {data art},
  owner = {dan},
  publicationstatus = {online-published},
  startday = {25},
  startmonth = {Oct},
  startyear = {2015},
  timestamp = {2016.04.04},
  url = {<a href="http://www.translatingdata.org/">http://www.translatingdata.org/</a>}
}
</pre>

<a name="Mycroft2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Mycroft2015">Mycroft2015</a>,
  title = {The effect of differing user interface presentation styles on audio mixing},
  author = {Mycroft, J and Reiss, JD and Stockman, T},
  year = {2015},
  conference = {International Conference on the Multimodal Experience of Music (ICMEM)},
  owner = {dan},
  school = {Sheffield},
  timestamp = {2016.04.04}
}
</pre>

<a name="Ronan2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Ronan2015">Ronan2015</a>,
  title = {The impact of subgrouping practices on the perception of multitrack mixes},
  author = {Ronan, DM and DeMan, B and Gunes, H and Reiss, JD},
  year = {2015},
  conference = {139th AES Convention},
  owner = {dan},
  school = {New York},
  timestamp = {2016.04.04}
}
</pre>

<a name="Jillings2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Jillings2015">Jillings2015</a>,
  title = {Web Audio Evaluation Tool: A Browser-based Listening Test Environment},
  author = {Jillings, N and Man, BD and Moffat, D and Reiss, JD},
  year = {2015},
  conference = {12th Sound and Music Computing Conference},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Zacharakis2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Zacharakis2015">Zacharakis2015</a>,
  title = {An interlanguage unification of musical timbre: Bridging semantic, perceptual, and acoustic dimensions},
  author = {Zacharakis, A and Pastiadis, K and Reiss, JD},
  journal = {Music Perception},
  year = {2015},
  month = {Jan},
  pages = {394--412},
  volume = {32},
  abstract = {The current study expands our previous work on interlanguage musical timbre semantics by examining the relationship between semantics and perception of timbre. Following Zacharakis, Pastiadis, and Reiss (2014), a pairwise dissimilarity listening test involving participants from two separate linguistic groups (Greek and English) was conducted. Subsequent multidimensional scaling analysis produced a 3D perceptual timbre space for each language. The comparison between perceptual spaces suggested that timbre perception is unaffected by native language. Additionally, comparisons between semantic and perceptual spaces revealed substantial similarities which suggest that verbal descriptions can convey a considerable amount of perceptual information. The previously determined semantic labels "auditory texture" and "luminance" featured the highest associations with perceptual dimensions for both languages. "Auditory mass" failed to show any strong correlations. Acoustic analysis identified energy distribution of harmonic partials, spectral detail, temporal/spectrotemporal characteristics and the fundamental frequency as the most salient acoustic correlates of perceptual dimensions.},
  day = {1},
  doi = {10.1525/MP.2015.32.4.394},
  eissn = {1533-8312},
  issn = {0730-7829},
  issue = {4},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Hafezi2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Hafezi2015">Hafezi2015</a>,
  title = {Autonomous Multitrack Equalization Based on Masking Reduction},
  author = {Hafezi, S and Reiss, JD},
  journal = {JOURNAL OF THE AUDIO ENGINEERING SOCIETY},
  year = {2015},
  month = {May},
  pages = {312--323},
  volume = {63},
  issn = {1549-4950},
  issue = {5},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04},
  url = {<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000355777700001\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000355777700001\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a</a>}
}
</pre>

<a name="Hon2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Hon2015">Hon2015</a>,
  title = {Audio fingerprinting for multi-device self-localization},
  author = {Hon, TK and Wang, L and Reiss, JD and Cavallaro, A},
  journal = {IEEE Transactions on Audio, Speech and Language Processing},
  year = {2015},
  month = {Oct},
  pages = {1623--1636},
  volume = {23},
  abstract = {We investigate the self-localization problem of an ad-hoc network of randomly distributed and independent devices in an open-space environment with low reverberation but heavy noise (e.g. smartphones recording videos of an outdoor event). Assuming a sufficient number of sound sources, we estimate the distance between a pair of devices from the extreme (minimum and maximum) time difference of arrivals (TDOAs) from the sources to the pair of devices without knowing the time offset. The obtained inter-device distances are then exploited to derive the geometrical configuration of the network. In particular, we propose a robust audio fingerprinting algorithm for noisy recordings and perform landmark matching to construct a histogram of the TDOAs of multiple sources. The extreme TDOAs can be estimated from this histogram. By using audio fingerprinting features, the proposed algorithm works robustly in very noisy environments. Experiments with free-field simulation and open-space recordings prove the effectiveness of the proposed algorithm.},
  day = {1},
  doi = {10.1109/TASLP.2015.2442417},
  issn = {1558-7916},
  issue = {10},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Mason2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Mason2015">Mason2015</a>,
  title = {Adaptive audio reproduction using personalised compression},
  author = {Mason, A and Jillings, N and Ma, Z and Reiss, JD and Melchior, F},
  booktitle = {Proceedings of the AES International Conference},
  year = {2015},
  month = {Jan},
  volume = {2015-January},
  abstract = {Audio quality is very important to broadcasters' audiences, and unwanted loudness variations do compromise the quality of experience for the listener. Dynamic range control applied by the broadcaster can go some way to avoiding problems but can never take the individual environment of the listener into account. The listening conditions are a significant factor to be taken into account when dynamic range control is applied. The web audio API provided by HTML5 offers the possibility of performing dynamic range control under the control of the listener, tailoring it optimally for their individual situation. We have developed a system that demonstrates that this is achievable in a modern web browser. The implementation controls the compressor based on environmental noise level measured using the microphone present in most mobile device audio players.},
  day = {1},
  isbn = {9781942220022},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Moffat2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Moffat2015">Moffat2015</a>,
  title = {An Evaluation of Audio Feature Extraction Toolboxes (honorable mention for Best Paper)},
  author = {Moffat, D and Ronan, D and Reiss, JD},
  year = {2015},
  conference = {18th International Conference on Digital Audio Effects (DAFx-15)},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Man2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Man2015">Man2015</a>,
  title = {Analysis of Peer Reviews in Music Production},
  author = {Man, BD and Reiss, JD},
  journal = {Journal on the Art of Record Production},
  year = {2015},
  volume = {10},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Mycroft2015a"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Mycroft2015a">Mycroft2015a</a>,
  title = {Audio Mixing Displays; The Influence of Overviews on Information Search and Critical Listening},
  author = {Mycroft, J and Reiss, JD and Stockman, T},
  year = {2015},
  conference = {International Symposium on Computer Music Modeling and Retrieval (CMMR)},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Ronan2015a"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Ronan2015a">Ronan2015a</a>,
  title = {Automatic subgrouping of multitrack audio},
  author = {Ronan, DM and Moffat, D and Gunes, H and Reiss, JD},
  year = {2015},
  conference = {18th Int. Conference on Digital Audio Effects (DAFx-15)},
  owner = {dan},
  school = {Trondheim, Norway},
  timestamp = {2016.04.04}
}
</pre>

<a name="Pestana2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Pestana2015">Pestana2015</a>,
  title = {Cross-Adaptive Polarity Switching Strategies for Optimization of Audio Mixes},
  author = {Pestana, P and Reiss, JD and Barbosa, A},
  year = {2015},
  conference = {138th Audio Engineering Society (AES) Convention},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Hon2015a"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Hon2015a">Hon2015a</a>,
  title = {Fine landmark-based synchronization of ad-hoc microphone arrays},
  author = {Hon, TK and Wang, L and Reiss, JD and Cavallaro, A},
  year = {2015},
  pages = {1341--1345},
  conference = {23rd European Signal Processing Conference (EUSIPCO)},
  owner = {dan},
  school = {Nice, France},
  timestamp = {2016.04.04}
}
</pre>

<a name="Durr2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Durr2015">Durr2015</a>,
  title = {Implementation and evaluation of dynamic level of audio detail},
  author = {Durr, G and Peixoto, L and Souza, M and Tanoue, R and Reiss, JD},
  year = {2015},
  conference = {AES 56th International Conference},
  owner = {dan},
  school = {London, UK},
  timestamp = {2016.04.04}
}
</pre>

<a name="Ma2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Ma2015">Ma2015</a>,
  title = {Intelligent multitrack dynamic range compression},
  author = {Ma, Z and De Man, B and Pestana, PDL and Black, DAA and Reiss, JD},
  journal = {AES: Journal of the Audio Engineering Society},
  year = {2015},
  month = {Jan},
  pages = {412--426},
  volume = {63},
  abstract = {We present an intelligent approach to multitrack dynamic range compression where all parameters are configured automatically based on side-chain feature extraction from the input signals. A method of adjustment experiment to explore how audio engineers set the ratio and threshold is described. We use multiple linear regression to model the relationship between different features and the experimental results. Parameter automations incorporate control assumptions based on this experiment and those derived from mixing literature and analysis. Subjective evaluation of the intelligent system is provided in the form of a multiple stimulus listening test where the system is compared against a no-compression mix, two human mixes, and an alternative approach. Results showed that mixes devised by our system are able to compete with or outperform manual mixes by semi-professionals under a variety of subjective criteria.},
  day = {1},
  doi = {10.17743/jaes.2015.0053},
  issn = {1549-4950},
  issue = {6},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="DeMan2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#DeMan2015">DeMan2015</a>,
  title = {Perceptual evaluation of music mixing practices},
  author = {De Man, B and Boerum, M and Leonard, B and King, R and Massenburg, G and Reiss, JD},
  booktitle = {138th Audio Engineering Society Convention 2015},
  year = {2015},
  month = {Jan},
  pages = {129--136},
  volume = {1},
  abstract = {The relation of music production practices to preference is still poorly understood. Due to the highly complex process of mixing music, few studies have been able to reliably investigate mixing engineering, as investigating one process parameter or feature without considering the correlation with other parameters inevitably oversimplifies the problem. In this work, we present an experiment where different mixes of different songs, obtained with a representative set of audio engineering tools, are rated by experienced subjects. The relation between the perceived mix quality and sonic features extracted from the mixes is investigated, and we find that a number of features correlate with quality.},
  day = {1},
  isbn = {9781510806597},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="McGregor2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#McGregor2015">McGregor2015</a>,
  title = {From Distributional Semantics to Conceptual Spaces: A Novel Computational Method for Concept Creation.},
  author = {McGregor, S and Agres, K and Purver, M and Wiggins, GA},
  journal = {J. Artificial General Intelligence},
  year = {2015},
  number = {1},
  pages = {55--86},
  volume = {6},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Griffiths2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Griffiths2015">Griffiths2015</a>,
  title = {Information-theoretic segmentation of natural language},
  author = {Griffiths, SS and McGinity, MM and Forth, J and Purver, M and Wiggins, GA},
  booktitle = {CEUR Workshop Proceedings},
  year = {2015},
  month = {Jan},
  pages = {54--67},
  volume = {1510},
  abstract = {We present computational experiments on language segmentation using a general information-theoretic cognitive model. We present a method which uses the statistical regularities of language to segment a continuous stream of symbols into "meaningful units" at a range of levels. Given a string of symbols-in the present approach, textual representations of phonemes-we attempt to find the syllables such as grea and sy (in the word greasy); words such as in, greasy, wash, and water ; and phrases such as in greasy wash water. The approach is entirely information-theoretic, and requires no knowledge of the units themselves; it is thus assumed to require only general cognitive abilities, and has previously been applied to music. We tested our approach on two spoken language corpora, and we discuss our results in the context of learning as a statistical processes.},
  day = {1},
  issn = {1613-0073},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Yuan2015"></a><pre>
@incollection{<a href="input/pubs2015_raw.html#Yuan2015">Yuan2015</a>,
  title = {Predicting emotion labels for Chinese microblog texts},
  author = {Yuan, Z and Purver, M},
  year = {2015},
  month = {Jan},
  pages = {129--149},
  volume = {602},
  abstract = {We describe an experiment into detecting emotions in texts on the Chinese microblog service SinaWeibo (www.weibo.com) using distant supervision via various author-supplied emotion labels (emoticons and smilies). Existing word segmentation tools proved unreliable; better accuracy was achieved using characterbased features. Higher-order n-grams proved to be useful features. Accuracy varied according to label and emotion: while smilies are used more often, emoticons are more reliable. Happiness is the most accurately predicted emotion, with accuracies around 90\% on both distant and gold-standard labels. This approach works well and achieves high accuracies for happiness and anger, while it is less effective for sadness, surprise, disgust and fear, which are also difficult for human annotators to detect.},
  day = {1},
  doi = {10.1007/978-3-319-18458-6_7},
  issn = {1860-949X},
  journal = {Studies in Computational Intelligence},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Eshghi2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Eshghi2015">Eshghi2015</a>,
  title = {Feedback in Conversation as Incremental Semantic Update},
  author = {Eshghi, A and Howes, C and Gregoromichelaki, E and Hough, J and Purver, M},
  booktitle = {Proceedings of the 11th International Conference on Computational Semantics},
  year = {2015},
  address = {London, UK},
  month = {Apr},
  pages = {261--271},
  publisher = {Association for Computational Linguistics},
  isbn = {978-1-941643-33-4},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.aclweb.org/anthology/W15-0130">http://www.aclweb.org/anthology/W15-0130</a>}
}
</pre>

<a name="Purver2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Purver2015">Purver2015</a>,
  title = {From Distributional Semantics to Distributional Pragmatics?},
  author = {Purver, M and Sadrzadeh, M},
  booktitle = {Proceedings of the IWCS 2015 Workshop on Interactive Meaning Construction},
  year = {2015},
  address = {London, UK},
  month = {Apr},
  pages = {21--22},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.eecs.qmul.ac.uk/\%20mpurver/papers/purver-sadrzadeh15imc.pdf">http://www.eecs.qmul.ac.uk/\%20mpurver/papers/purver-sadrzadeh15imc.pdf</a>}
}
</pre>

<a name="Sadrzadeh2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Sadrzadeh2015">Sadrzadeh2015</a>,
  title = {Geometry of Meaning from Words to Dialogue Acts},
  author = {Sadrzadeh, M and Purver, M},
  booktitle = {Proceedings of the IWCS 2015 Workshop on Advances in Distributional Semantics},
  year = {2015},
  address = {London, UK},
  month = apr,
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.eecs.qmul.ac.uk/\%20mpurver/papers/sadrzadeh-purver15ads.pdf">http://www.eecs.qmul.ac.uk/\%20mpurver/papers/sadrzadeh-purver15ads.pdf</a>}
}
</pre>

<a name="McGregor2015a"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#McGregor2015a">McGregor2015a</a>,
  title = {Metaphor, meaning, computers and consciousness},
  author = {McGregor, S and Purver, M and Wiggins, G},
  booktitle = {AISB Convention 2015},
  year = {2015},
  month = {Jan},
  abstract = {This paper seeks to situate the computational modelling of metaphor within the context of questions about the relationship between the meaning and use of language. The results of this pragmatic assessment are used as the theoretical basis for a proposed computational implementation that seeks metaphor in the geometry of a vector space model of distributional semantics. This statistical approach to the analysis and generation of metaphor is taken as a platform for a consideration of the fraught relationship between computational models of cognitive processes and the study of consciousness.},
  day = {1},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Agres2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Agres2015">Agres2015</a>,
  title = {Conceptualizing Creativity: From Distributional Semantics to Conceptual Spaces},
  author = {Agres, K and McGregor, S and Purver, M and Wiggins, G},
  booktitle = {Proceedings of the 6th International Conference on Computational Creativity (ICCC)},
  year = {2015},
  address = {Park City, UT},
  month = {Jun},
  pages = {118--125},
  isbn = {978-0-8425-2970-9},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.eecs.qmul.ac.uk/\%20mpurver/papers/agres-et-al15iccc.pdf">http://www.eecs.qmul.ac.uk/\%20mpurver/papers/agres-et-al15iccc.pdf</a>}
}
</pre>

<a name="McGregor2015b"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#McGregor2015b">McGregor2015b</a>,
  title = {An Emergent Model of Metaphors as Transformations of Vector Spaces},
  author = {McGregor, S and Purver, M and Wiggins, G},
  booktitle = {Proceedings of the 13th International Cognitive Linguistics Conference (ICLC)},
  year = {2015},
  address = {Newcastle-upon-Tyne},
  month = {Jul},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.eecs.qmul.ac.uk/\%20mpurver/papers/mcgregor-et-al15iclc.pdf">http://www.eecs.qmul.ac.uk/\%20mpurver/papers/mcgregor-et-al15iclc.pdf</a>}
}
</pre>

<a name="Mylonas2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Mylonas2015">Mylonas2015</a>,
  title = {The Use of English Colour Terms in Big Data},
  author = {Mylonas, D and Purver, M and Sadrzadeh, M and MacDonald, L and Griffin, L},
  booktitle = {Proceedings of the 2015 Meeting of the International Colour Association (AIC)},
  year = {2015},
  address = {Tokyo},
  month = {May},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.eecs.qmul.ac.uk/\%20mpurver/papers/mylonas-et-al15aic.pdf">http://www.eecs.qmul.ac.uk/\%20mpurver/papers/mylonas-et-al15aic.pdf</a>}
}
</pre>

<a name="Kempson2015"></a><pre>
@incollection{<a href="input/pubs2015_raw.html#Kempson2015">Kempson2015</a>,
  title = {Ellipsis},
  author = {Kempson, R and Cann, R and Eshghi, A and Gregoromichelaki, E and Purver, M},
  booktitle = {Handbook of Contemporary Semantic Theory},
  publisher = {Wiley},
  year = {2015},
  edition = {2nd},
  editor = {Lappin, S and Fox, C},
  month = {Sep},
  number = {4},
  isbn = {978-0-470-67073-6},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470670738.html">http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470670738.html</a>}
}
</pre>

<a name="Sylwester2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Sylwester2015">Sylwester2015</a>,
  title = {Twitter Language Use Reflects Psychological Differences between Democrats and Republicans},
  author = {Sylwester, K and Purver, M},
  journal = {PLOS ONE},
  year = {2015},
  month = {Sep},
  pages = {e0137422--e0137422},
  volume = {10},
  day = {16},
  doi = {10.1371/journal.pone.0137422},
  editor = {Danforth, CM},
  eissn = {1932-6203},
  issue = {9},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Carey2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Carey2015">Carey2015</a>,
  title = {Generality and specificity in the effects of musical expertise on perception and cognition.},
  author = {Carey, D and Rosen, S and Krishnan, S and Pearce, MT and Shepherd, A and Aydelott, J and Dick, F},
  journal = {Cognition},
  year = {2015},
  month = {Apr},
  pages = {81--105},
  volume = {137},
  abstract = {Performing musicians invest thousands of hours becoming experts in a range of perceptual, attentional, and cognitive skills. The duration and intensity of musicians' training - far greater than that of most educational or rehabilitation programs - provides a useful model to test the extent to which skills acquired in one particular context (music) generalize to different domains. Here, we asked whether the instrument-specific and more instrument-general skills acquired during professional violinists' and pianists' training would generalize to superior performance on a wide range of analogous (largely non-musical) skills, when compared to closely matched non-musicians. Violinists and pianists outperformed non-musicians on fine-grained auditory psychophysical measures, but surprisingly did not differ from each other, despite the different demands of their instruments. Musician groups did differ on a tuning system perception task: violinists showed clearest biases towards the tuning system specific to their instrument, suggesting that long-term experience leads to selective perceptual benefits given a training-relevant context. However, we found only weak evidence of group differences in non-musical skills, with musicians differing marginally in one measure of sustained auditory attention, but not significantly on auditory scene analysis or multi-modal sequencing measures. Further, regression analyses showed that this sustained auditory attention metric predicted more variance in one auditory psychophysical measure than did musical expertise. Our findings suggest that specific musical expertise may yield distinct perceptual outcomes within contexts close to the area of training. Generalization of expertise to relevant cognitive domains may be less clear, particularly where the task context is non-musical.},
  address = {Centre for Brain and Cognitive Development, Birkbeck College, University of London, UK; Department of Psychological Sciences, Birkbeck College, University of London, UK. Electronic address: d.carey@bbk.ac.uk.},
  doi = {10.1016/j.cognition.2014.12.005},
  eissn = {1873-7838},
  howpublished = {Print-Electronic},
  issn = {0010-0277},
  language = {eng},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Pearce2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Pearce2015">Pearce2015</a>,
  title = {Age-Related Patterns in Emotions Evoked by Music},
  author = {Pearce, MT and Halpern, AR},
  journal = {PSYCHOLOGY OF AESTHETICS CREATIVITY AND THE ARTS},
  year = {2015},
  month = {Aug},
  pages = {248--253},
  volume = {9},
  doi = {10.1037/a0039279},
  issn = {1931-3896},
  issue = {3},
  keyword = {aging},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04},
  url = {<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000359379300007\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000359379300007\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a</a>}
}
</pre>

<a name="Jack2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Jack2015">Jack2015</a>,
  title = {The design of tactile musical devices for the deaf},
  author = {Jack, RH and MCPHERSON, A and Stockman, T},
  year = {2015},
  organization = {Sheffield, UK},
  conference = {International Conference on the Multimodal Experience of Music},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="MacRitchie2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#MacRitchie2015">MacRitchie2015</a>,
  title = {Integrating optical finger motion tracking with surface touch events},
  author = {MacRitchie, J and McPherson, AP},
  journal = {Frontiers in Psychology},
  year = {2015},
  month = {Jun},
  volume = {6},
  day = {2},
  doi = {10.3389/fpsyg.2015.00702},
  eissn = {1664-1078},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Pardue2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Pardue2015">Pardue2015</a>,
  title = {A Low-Cost Real-Time Tracking System for Violin},
  author = {Pardue, LS and Harte, C and McPherson, AP},
  journal = {JOURNAL OF NEW MUSIC RESEARCH},
  year = {2015},
  month = {Oct},
  pages = {305--323},
  volume = {44},
  day = {2},
  doi = {10.1080/09298215.2015.1087575},
  issn = {0929-8215},
  issue = {4},
  keyword = {violin},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04},
  url = {<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000366320300002\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000366320300002\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a</a>}
}
</pre>

<a name="Donovan2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Donovan2015">Donovan2015</a>,
  title = {Active control of a string instrument bridge using the Posicast technique},
  author = {Donovan, L and MCPHERSON, A},
  year = {2015},
  organization = {Warsaw, Poland},
  conference = {138th Audio Engineering Society Convention},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="McPherson2015b"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#McPherson2015b">McPherson2015b</a>,
  title = {An environment for submillisecond-latency audio and sensor processing on BeagleBone Black},
  author = {McPherson, A and Zappi, V},
  year = {2015},
  organization = {Warsaw, Poland},
  conference = {138th Audio Engineering Society Convention},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="McPherson2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#McPherson2015">McPherson2015</a>,
  title = {Buttons, Handles, and Keys: Advances in Continuous-Control Keyboard Instruments},
  author = {McPherson, A},
  journal = {COMPUTER MUSIC JOURNAL},
  year = {2015},
  pages = {28--46},
  volume = {39},
  doi = {10.1162/COMJ_a_00297},
  issn = {0148-9267},
  issue = {2},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04},
  url = {<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000355321900002\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000355321900002\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a</a>}
}
</pre>

<a name="Zappi2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Zappi2015">Zappi2015</a>,
  title = {Exposing the scaffolding of digital instruments with hardware-software feedback loops},
  author = {Zappi, V and MCPHERSON, A},
  year = {2015},
  organization = {Baton Rouge, USA},
  conference = {New Interfaces for Musical Expression},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Menzies2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Menzies2015">Menzies2015</a>,
  title = {Highland piping ornament recognition using Dynamic Time Warping},
  author = {Menzies, DWH and MCPHERSON, A},
  year = {2015},
  organization = {Baton Rouge, USA},
  conference = {New Interfaces for Musical Expression},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Concannon2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Concannon2015">Concannon2015</a>,
  title = {Shifting Opinions: Experiments on Agreement and Disagreement in Dialogue},
  author = {Concannon, S and Healey, P and Purver, M},
  booktitle = {Proceedings of the 19th SemDial Workshop on the Semantics and Pragmatics of Dialogue (goDIAL)},
  year = {2015},
  address = {Gothenburg},
  month = {Aug},
  organization = {Gothenberg, Sweden},
  pages = {15--23},
  conference = {19th SemDial Workshop on the Semantics and Pragmatics of Dialogue (goDIAL)},
  finishday = {26},
  finishmonth = {Aug},
  finishyear = {2015},
  issn = {2308-2275},
  owner = {dan},
  publicationstatus = {published},
  startday = {24},
  startmonth = {Aug},
  startyear = {2015},
  timestamp = {2016.04.04},
  url = {<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/concannon-et-al15semdialexp.pdf">http://www.eecs.qmul.ac.uk/~mpurver/papers/concannon-et-al15semdialexp.pdf</a>}
}
</pre>

<a name="Concannon2015a"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Concannon2015a">Concannon2015a</a>,
  title = {Taking a Stance: a Corpus Study of Reported Speech},
  author = {Concannon, S and Healey, PGT and Purver, M},
  booktitle = {Proceedings of the 19th SemDial Workshop on the Semantics and Pragmatics of Dialogue (goDIAL)},
  year = {2015},
  address = {Gothenburg},
  month = {Aug},
  organization = {Gothenburg, Sweden},
  pages = {6--14},
  conference = {19th SemDial Workshop on the Semantics and Pragmatics of Dialogue (goDIAL)},
  finishday = {25},
  finishmonth = {Aug},
  finishyear = {2015},
  issn = {2308-2275},
  owner = {dan},
  publicationstatus = {published},
  startday = {23},
  startmonth = {Aug},
  startyear = {2015},
  timestamp = {2016.04.04},
  url = {<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/concannon-et-al15semdialcorpus.pdf">http://www.eecs.qmul.ac.uk/~mpurver/papers/concannon-et-al15semdialcorpus.pdf</a>}
}
</pre>

<a name="Katevas2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Katevas2015">Katevas2015</a>,
  title = {Robot Comedy Lab: experimenting with the social dynamics of live performance},
  author = {Katevas, K and Healey, PGT and Harris, MT},
  journal = {FRONTIERS IN PSYCHOLOGY},
  year = {2015},
  month = {Aug},
  number = {ARTN 1253},
  volume = {6},
  day = {25},
  doi = {10.3389/fpsyg.2015.01253},
  issn = {1664-1078},
  keyword = {human robot interaction},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04},
  url = {<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000360045400001\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a">http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000360045400001\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=612ae0d773dcbdba3046f6df545e9f6a</a>}
}
</pre>

<a name="Tubb2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Tubb2015">Tubb2015</a>,
  title = {An Evaluation of Multidimensional Controllers for Sound Design Tasks},
  author = {Tubb, R and Dixon, S},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year = {2015},
  publisher = {ACM},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Dai2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Dai2015">Dai2015</a>,
  title = {Analysis of Intonation Trajectories in Solo Singing},
  author = {Dai, J and Mauch, M and Dixon, S},
  booktitle = {16th International Society for Music Information Retrieval Conference},
  year = {2015},
  pages = {420--426},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Sigtia2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Sigtia2015">Sigtia2015</a>,
  title = {Audio Chord Recognition with a Hybrid Recurrent Neural Network.},
  author = {Sigtia, S and Boulanger-Lewandowski, N and Dixon, S},
  booktitle = {ISMIR},
  year = {2015},
  editor = {Muller, M and Wiering, F},
  pages = {127--133},
  isbn = {978-84-606-8853-2},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.informatik.uni-trier.de/~ley/db/conf/ismir/ismir2015.html">http://www.informatik.uni-trier.de/~ley/db/conf/ismir/ismir2015.html</a>}
}
</pre>

<a name="Wilmering2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Wilmering2015">Wilmering2015</a>,
  title = {Automating Annotation of Media with Linked Data Workflows},
  author = {Wilmering, T and Bechhofer, S and Dixon, S and Fazekas, G and Page, K},
  booktitle = {Third International Workshop on Linked Media (LiME 2015), Proceedings of the 24th International Conference on World Wide Web Companion},
  year = {2015},
  pages = {737--738},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Osmalskyj2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Osmalskyj2015">Osmalskyj2015</a>,
  title = {Combining Features for Cover Song Identification},
  author = {Osmalskyj, J and Foster, P and Dixon, S and Embrechts, J-J},
  booktitle = {16th International Society for Music Information Retrieval Conference},
  year = {2015},
  pages = {462--468},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Cheng2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Cheng2015">Cheng2015</a>,
  title = {Modelling the Decay of Piano Sounds},
  author = {Cheng, T and Dixon, S and Mauch, M},
  booktitle = {IEEE International Conference on Acoustics Speech and Signal Processing},
  year = {2015},
  pages = {594--598},
  conference = {IEEE International Conference on Acoustics Speech and Signal Processing},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Wang2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Wang2015">Wang2015</a>,
  title = {Compensating for asynchronies between musical voices in score-performance alignment},
  author = {Wang, S and Ewert, S and Dixon, S},
  booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  year = {2015},
  month = {Jan},
  pages = {589--593},
  volume = {2015-August},
  abstract = {The goal of score-performance synchronisation is to align a given musical score to an audio recording of a performance of the same piece. A major challenge in computing such alignments is to account for musical parameters including the local tempo or playing style. To increase the overall robustness, current methods assume that notes occurring simultaneously in the score are played concurrently in a performance. Musical voices such as the melody, however, are often played asynchronously to other voices, which can lead to significant local alignment errors. In this paper, we present a novel method that handles asynchronies between the melody and the accompaniment by treating the voices as separate timelines in a multi-dimensional variant of dynamic time warping (DTW). Constraining the alignment with information obtained via classical DTW, our method measurably improves the alignment accuracy for pieces with asynchronous voices and preserves the accuracy otherwise.},
  day = {1},
  doi = {10.1109/ICASSP.2015.7178037},
  isbn = {9781467369978},
  issn = {1520-6149},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Sigtia2015a"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Sigtia2015a">Sigtia2015a</a>,
  title = {A hybrid recurrent neural network for music transcription},
  author = {Sigtia, S and Benetos, E and Boulanger-Lewandowski, N and Weyde, T and D'Avila Garcez, AS and Dixon, S},
  booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  year = {2015},
  month = {Jan},
  pages = {2061--2065},
  volume = {2015-August},
  abstract = {We investigate the problem of incorporating higher-level symbolic score-like information into Automatic Music Transcription (AMT) systems to improve their performance. We use recurrent neural networks (RNNs) and their variants as music language models (MLMs) and present a generative architecture for combining these models with predictions from a frame level acoustic classifier. We also compare different neural network architectures for acoustic modeling. The proposed model computes a distribution over possible output sequences given the acoustic input signal and we present an algorithm for performing a global search for good candidate transcriptions. The performance of the proposed model is evaluated on piano music from the MAPS dataset and we observe that the proposed model consistently outperforms existing transcription methods.},
  day = {1},
  doi = {10.1109/ICASSP.2015.7178333},
  isbn = {9781467369978},
  issn = {1520-6149},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Song2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Song2015">Song2015</a>,
  title = {How Well Can a Music Emotion Recognition System Predict the Emotional Responses of Participants?},
  author = {Song, Y and Dixon, S},
  booktitle = {12th International Conference on Sound and Music Computing},
  year = {2015},
  pages = {387--392},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Mauch2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Mauch2015">Mauch2015</a>,
  title = {Computer-aided Melody Note Transcription Using the Tony Software: Accuracy and Efficiency},
  author = {Mauch, M and Cannam, C and Bittner, R and Fazekas, G and Salamon, J and Dai, J and Bello, J and Dixon, S},
  booktitle = {First International Conference on Technologies for Music Notation and Representation (TENOR 2015)},
  year = {2015},
  pages = {23--30},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Foster2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Foster2015">Foster2015</a>,
  title = {Identifying Cover Songs Using Information-Theoretic Measures of Similarity},
  author = {Foster, P and Dixon, S and Klapuri, A},
  journal = {IEEE Transactions on Audio, Speech and Language Processing},
  year = {2015},
  month = {Jun},
  pages = {993--1005},
  volume = {23},
  abstract = {This paper investigates methods for quantifying similarity between audio signals, specifically for the task of cover song detection. We consider an information-theoretic approach, where we compute pairwise measures of predictability between time series. We compare discrete-valued approaches operating on quantized audio features, to continuous-valued approaches. In the discrete case, we propose a method for computing the normalized compression distance, where we account for correlation between time series. In the continuous case, we propose to compute information-based measures of similarity as statistics of the prediction error between time series. We evaluate our methods on two cover song identification tasks using a data set comprised of 300 Jazz standards and using the Million Song Dataset. For both datasets, we observe that continuous-valued approaches outperform discrete-valued approaches. We consider approaches to estimating the normalized compression distance (NCD) based on string compression and prediction, where we observe that our proposed normalized compression distance with alignment (NCDA) improves average performance over NCD, for sequential compression algorithms. Finally, we demonstrate that continuous-valued distances may be combined to improve performance with respect to baseline approaches. Using a large-scale filter-and-refine approach, we demonstrate state-of-the-art performance for cover song identification using the Million Song Dataset.},
  day = {1},
  doi = {10.1109/TASLP.2015.2416655},
  issn = {1558-7916},
  issue = {6},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Bengler2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Bengler2015">Bengler2015</a>,
  title = {"I could play here for hours.." (thinks the visitor and leaves): Why People Disengage from Public Interactives.},
  author = {Bengler, B and Bryan-Kinns, N},
  booktitle = {Creativity \& Cognition},
  year = {2015},
  editor = {Maver, T and Do, EY-L},
  pages = {177--180},
  publisher = {ACM},
  doi = {10.1145/2757226.2764548},
  isbn = {978-1-4503-3598-0},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://dl.acm.org/citation.cfm?id=2757226">http://dl.acm.org/citation.cfm?id=2757226</a>}
}
</pre>

<a name="Morgan2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Morgan2015">Morgan2015</a>,
  title = {The LuminUs: Providing musicians with visual feedback on the gaze and body motion of their co-performers},
  author = {Morgan, E and Gunes, H and Bryan-Kinns, N},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year = {2015},
  month = {Jan},
  pages = {47--54},
  volume = {9297},
  abstract = {This paper describes the LuminUs-a device that we designed in order to explore how new technologies could influence the inter-personal aspects of co-present musical collaborations. The LuminUs uses eye-tracking headsets and small wireless accelerometers to measure the gaze and body motion of each musician. A small light display then provides visual feedback to each musician, based either on the gaze or the body motion of their co-performer. We carried out an experiment with 15 pairs of music students in order to investigate how the LuminUs would influence their musical interactions. Preliminary results suggest that visual feedback provided by the LuminUs led to significantly increased glancing between the two musicians, whilst motion based feedback appeared to lead to a decrease in body motion for both participants.},
  day = {1},
  doi = {10.1007/978-3-319-22668-2_4},
  eissn = {1611-3349},
  isbn = {9783319226675},
  issn = {0302-9743},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Metatla2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Metatla2015">Metatla2015</a>,
  title = {Sonification of reference markers for auditory graphs: Effects on non-visual point estimation tasks.},
  author = {Metatla, O and Bryan-Kinns, N and Stockman, T and Martin, F},
  journal = {PeerJ PrePrints},
  year = {2015},
  pages = {e1376--e1376},
  volume = {3},
  doi = {10.7287/peerj.preprints.1376v1},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="Morgan2015a"></a><pre>
@article{<a href="input/pubs2015_raw.html#Morgan2015a">Morgan2015a</a>,
  title = {Using affective and behavioural sensors to explore aspects of collaborative music making},
  author = {Morgan, E and Gunes, H and Bryan-Kinns, N},
  journal = {International Journal of Human Computer Studies},
  year = {2015},
  month = {May},
  pages = {31--47},
  volume = {82},
  abstract = {Our research considers the role that new technologies could play in supporting emotional and non-verbal interactions between musicians during co-present music making. To gain a better understanding of the underlying affective and communicative processes that occur during such interactions, we carried out an exploratory study where we collected self-report and continuous behavioural and physiological measures from pairs of improvising drummers. Our analyses revealed interesting relationships between creative decisions and changes in heart rate. Self-reported measures of creativity, engagement, and energy were correlated with body motion; whilst EEG beta-band activity was correlated with self-reported positivity and leadership. Regarding co-visibility, lack of visual contact between musicians had a negative influence on self reported creativity. The number of glances between musicians was positively correlated with rhythmic synchrony, and the average length of glances was correlated with self-reported boredom. Our results indicate that ECG, motion, and glance measurements could be particularly suitable for the investigation of collaborative music making.},
  day = {30},
  doi = {10.1016/j.ijhcs.2015.05.002},
  eissn = {1095-9300},
  issn = {1071-5819},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Metatla2015a"></a><pre>
@article{<a href="input/pubs2015_raw.html#Metatla2015a">Metatla2015a</a>,
  title = {Designing with and for people living with visual impairments: audio-tactile mock-ups, audio diaries and participatory prototyping},
  author = {Metatla, O and Bryan-Kinns, N and Stockman, T and Martin, F},
  journal = {CoDesign},
  year = {2015},
  month = {Jan},
  pages = {35--48},
  volume = {11},
  abstract = {Methods used to engage users in the design process often rely on visual techniques, such as paper prototypes, to facilitate the expression and communication of design ideas. The visual nature of these tools makes them inaccessible to people living with visual impairments. In addition, while using visual means to express ideas for designing graphical interfaces is appropriate, it is harder to use them to articulate the design of non-visual displays. In this article, we present an approach to conducting participatory design with people living with visual impairments incorporating various techniques to help make the design process accessible. We reflect on the benefits and challenges that we encountered when employing these techniques in the context of designing cross-modal interactive tools.},
  day = {1},
  doi = {10.1080/15710882.2015.1007877},
  eissn = {1745-3755},
  issn = {1571-0882},
  issue = {1},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Mazzoni2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Mazzoni2015">Mazzoni2015</a>,
  title = {How Does It Feel Like? An Exploratory Study of a Prototype System to Convey Emotion through Haptic Wearable Devices.},
  author = {Mazzoni, A and Bryan-Kinns, N},
  journal = {ICST Trans. e-Education e-Learning},
  year = {2015},
  number = {8},
  pages = {e2--e2},
  volume = {2},
  doi = {10.4108/icst.intetain.2015.259625},
  owner = {dan},
  timestamp = {2016.04.04}
}
</pre>

<a name="McDonald2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#McDonald2015">McDonald2015</a>,
  title = {Nature Bot: Experiencing Nature in the Built Environment.},
  author = {McDonald, S and Kirk, DS and Bryan-Kinns, N},
  booktitle = {Creativity \& Cognition},
  year = {2015},
  editor = {Maver, T and Do, EY-L},
  pages = {173--176},
  publisher = {ACM},
  doi = {10.1145/2757226.2764547},
  isbn = {978-1-4503-3598-0},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://dl.acm.org/citation.cfm?id=2757226">http://dl.acm.org/citation.cfm?id=2757226</a>}
}
</pre>

<a name="Mazzoni2015a"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Mazzoni2015a">Mazzoni2015a</a>,
  title = {How does it feel like? An exploratory study of a prototype system to convey emotion through haptic wearable devices},
  author = {Mazzoni, A and Bryan-Kinns, N},
  booktitle = {Proceedings of the 2015 7th International Conference on Intelligent Technologies for Interactive Entertainment, INTETAIN 2015},
  year = {2015},
  month = {Nov},
  pages = {64--68},
  abstract = {This paper reports on the design and implementation of a portable, hands-free, wearable haptic device that maps the emotions evoked by the music in a movie into vibrations, with the aim that hearing-impaired audience can get a sense of the emotional content carried by the music in specific movie scenes, and therefore feel (hear) the music through the sense of touch. A study of the use of the technology is reported which found that high arousal and high valence were reliably conveyed through haptic patterns with high intensity and high frequency, whereas haptic patterns with low intensity and low frequency conveyed low arousal and low valence.},
  day = {10},
  doi = {10.4108/icst.intetain.2015.259625},
  isbn = {9781631900617},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Abdallah2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Abdallah2015">Abdallah2015</a>,
  title = {Automatic transcription and pitch analysis of the British Library World \& Traditional Music Collection},
  author = {Abdallah, S and Alencar-Brayner, A and BENETOS, E and Cottrell, S and Dykes, J and Gold, N and Kachkaev, A and Mahey, M and Tidhar, D and Tovell, A and Weyde, T and Wolff, D},
  booktitle = {<a href="http://fma2015.sciencesconf.org/conference/fma2015/FMA2015_OfficialProceedings.pdf">http://fma2015.sciencesconf.org/conference/fma2015/FMA2015_OfficialProceedings.pdf</a>},
  year = {2015},
  month = {Jun},
  organization = {Paris, France},
  pages = {10--12},
  publisher = {Association Dirac},
  conference = {5th International Workshop on Folk Music Analysis},
  day = {10},
  finishday = {12},
  finishmonth = {Jun},
  finishyear = {2015},
  isbn = {9-791095-209003},
  owner = {dan},
  publicationstatus = {published},
  startday = {10},
  startmonth = {Jun},
  startyear = {2015},
  timestamp = {2016.04.04}
}
</pre>

<a name="Benetos2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Benetos2015">Benetos2015</a>,
  title = {Automatic transcription of Turkish microtonal music},
  author = {Benetos, E and Holzapfel, A},
  journal = {Journal of the Acoustical Society of America},
  year = {2015},
  month = {Oct},
  pages = {2118--2130},
  volume = {138},
  abstract = {Automatic music transcription, a central topic in music signal analysis, is typically limited to equal-tempered music and evaluated on a quartertone tolerance level. A system is proposed to automatically transcribe microtonal and heterophonic music as applied to the makam music of Turkey. Specific traits of this music that deviate from properties targeted by current transcription tools are discussed, and a collection of instrumental and vocal recordings is compiled, along with aligned microtonal reference pitch annotations. An existing multi-pitch detection algorithm is adapted for transcribing music with 20 cent resolution, and a method for converting a multi-pitch heterophonic output into a single melodic line is proposed. Evaluation metrics for transcribing microtonal music are applied, which use various levels of tolerance for inaccuracies with respect to frequency and time. Results show that the system is able to transcribe microtonal instrumental music at 20 cent resolution with an F-measure of 56.7\%, outperforming state-of-the-art methods for the same task. Case studies on transcribed recordings are provided, to demonstrate the shortcomings and the strengths of the proposed method.},
  day = {1},
  doi = {10.1121/1.4930187},
  issn = {0001-4966},
  issue = {4},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Rossignol2015"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Rossignol2015">Rossignol2015</a>,
  title = {Alternate level clustering for drum transcription.},
  author = {Rossignol, M and Lagrange, M and Lafay, G and Benetos, E},
  booktitle = {EUSIPCO},
  year = {2015},
  pages = {2023--2027},
  publisher = {IEEE},
  doi = {10.1109/EUSIPCO.2015.7362739},
  isbn = {978-0-9928-6263-3},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7362053">http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7362053</a>}
}
</pre>

<a name="Stowell2015"></a><pre>
@article{<a href="input/pubs2015_raw.html#Stowell2015">Stowell2015</a>,
  title = {Detection and Classification of Acoustic Scenes and Events},
  author = {Stowell, D and Giannoulis, D and Benetos, E and Lagrange, M and Plumbley, MD},
  journal = {IEEE Transactions on Multimedia},
  year = {2015},
  month = {Oct},
  pages = {1733--1746},
  volume = {17},
  abstract = {For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.},
  day = {1},
  doi = {10.1109/TMM.2015.2428998},
  issn = {1520-9210},
  issue = {10},
  owner = {dan},
  publicationstatus = {published},
  timestamp = {2016.04.04}
}
</pre>

<a name="Benetos2015a"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Benetos2015a">Benetos2015a</a>,
  title = {An Efficient Temporally-Constrained Probabilistic Model for Multiple-Instrument Music Transcription.},
  author = {Benetos, E and Weyde, T},
  booktitle = {ISMIR},
  year = {2015},
  editor = {Muller, M and Wiering, F},
  pages = {701--707},
  isbn = {978-84-606-8853-2},
  owner = {dan},
  timestamp = {2016.04.04},
  url = {<a href="http://www.informatik.uni-trier.de/~ley/db/conf/ismir/ismir2015.html">http://www.informatik.uni-trier.de/~ley/db/conf/ismir/ismir2015.html</a>}
}
</pre>

<a name="Sigtia2015b"></a><pre>
@inproceedings{<a href="input/pubs2015_raw.html#Sigtia2015b">Sigtia2015b</a>,
  title = {A Hybrid Recurrent Neural Network for Music Transcription},
  author = {Sigtia, S and Benetos, E and Boulanger-Lewandowski, N and Weyde, T and Garcez, ASDA and Dixon, S},
  booktitle = {IEEE International Conference on Acoustics Speech and Signal Processing},
  year = {2015},
  month = {Apr},
  organization = {Brisbane, Australia},
  pages = {2061--2065},
  publisher = {IEEE},
  conference = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  day = {19},
  doi = {10.1109/ICASSP.2015.7178333},
  finishday = {24},
  finishmonth = {Apr},
  finishyear = {2015},
  owner = {dan},
  publicationstatus = {published},
  startday = {19},
  startmonth = {Apr},
  startyear = {2015},
  timestamp = {2016.04.04},
  url = {<a href="http://www.ieee.org/">http://www.ieee.org/</a>}
}
</pre>

<hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.97.</em></p>
